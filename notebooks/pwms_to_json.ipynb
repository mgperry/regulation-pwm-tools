{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reading in various PFM datasets\n",
    "\n",
    "The closest thing to a standard we seem to have is to write PFMs to a single file, with 4 lines specifying the `[ACGT]` counts and bases 1..N preceeded by a header line, separated either by commas or tabs. The `pfm_reader` function expects a file (or set of lines) in this form. The header is split out into its component parts (which change depending on the source file), and the counts are split and then the number fields are extracted and turned into a matrix (technically `list[list[int]]`).\n",
    "\n",
    "The 'id' field I've created here is to match the IDs used in the ENCODE Fooprinting Paper [Veerstra et al., Nature 2020], it's very ad hoc and definitely not suitable for production use. It would also be possible to pull in metadata while we read in the PFMs and output that straight into the JSON, `ENSG` in particular would be very useful, as would filtering out non-human TFs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "import collections\n",
    "from tfbs.pfm_reader import pfm_reader\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "all_pfms = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "jaspar_pfms = []\n",
    "\n",
    "with open(\"data/JASPAR2018_CORE_vertebrates_non-redundant_pfms_jaspar.txt\") as jaspar:\n",
    "    for pfm in pfm_reader(jaspar):\n",
    "        pfm['jaspar_id'] = pfm['info'][0]\n",
    "        pfm['symbol'] = pfm['info'][1]\n",
    "        pfm['id'] = pfm['symbol'] + \"_\" + pfm['jaspar_id']\n",
    "        pfm['source'] = \"JASPAR2018\"\n",
    "        jaspar_pfms.append(pfm)\n",
    "\n",
    "print(json.dumps(jaspar_pfms[:1], indent=4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"info\": [\n",
      "            \"MA0004.1\",\n",
      "            \"Arnt\"\n",
      "        ],\n",
      "        \"PFM\": [\n",
      "            [\n",
      "                4,\n",
      "                19,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0\n",
      "            ],\n",
      "            [\n",
      "                16,\n",
      "                0,\n",
      "                20,\n",
      "                0,\n",
      "                0,\n",
      "                0\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                1,\n",
      "                0,\n",
      "                20,\n",
      "                0,\n",
      "                20\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                20,\n",
      "                0\n",
      "            ]\n",
      "        ],\n",
      "        \"jaspar_id\": \"MA0004.1\",\n",
      "        \"symbol\": \"Arnt\",\n",
      "        \"id\": \"Arnt_MA0004.1\",\n",
      "        \"source\": \"JASPAR2018\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "hoco_pfms = []\n",
    "\n",
    "with open(\"data/HOCOMOCOv11_core_HUMAN_mono_jaspar_format.txt\") as hoco:\n",
    "    for pfm in pfm_reader(hoco):\n",
    "        pfm['id'] = pfm['info'][0]\n",
    "        pfm['source'] = \"HOCOMOCOv11\"\n",
    "        hoco_pfms.append(pfm)\n",
    "\n",
    "print(json.dumps(hoco_pfms[:1], indent=4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"info\": [\n",
      "            \"AHR_HUMAN.H11MO.0.B\"\n",
      "        ],\n",
      "        \"PFM\": [\n",
      "            [\n",
      "                41,\n",
      "                11,\n",
      "                22,\n",
      "                3,\n",
      "                1,\n",
      "                3,\n",
      "                0,\n",
      "                0,\n",
      "                43\n",
      "            ],\n",
      "            [\n",
      "                18,\n",
      "                12,\n",
      "                44,\n",
      "                1,\n",
      "                150,\n",
      "                1,\n",
      "                3,\n",
      "                0,\n",
      "                67\n",
      "            ],\n",
      "            [\n",
      "                56,\n",
      "                35,\n",
      "                21,\n",
      "                146,\n",
      "                1,\n",
      "                149,\n",
      "                1,\n",
      "                154,\n",
      "                16\n",
      "            ],\n",
      "            [\n",
      "                39,\n",
      "                96,\n",
      "                67,\n",
      "                4,\n",
      "                2,\n",
      "                1,\n",
      "                150,\n",
      "                0,\n",
      "                28\n",
      "            ]\n",
      "        ],\n",
      "        \"id\": \"AHR_HUMAN.H11MO.0.B\",\n",
      "        \"source\": \"HOCOMOCOv11\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "taipale_pfms = []\n",
    "\n",
    "with open(\"data/taipale_pwms.csv\") as taipale:\n",
    "    lines = taipale.readlines()[17:] # skip header\n",
    "    tf_counter = collections.Counter()\n",
    "    for pfm in pfm_reader(lines, delimiter=\",\"):\n",
    "        pfm['symbol'] = pfm['info'][0]\n",
    "        pfm['tf_class'] = pfm['info'][1]\n",
    "        id = pfm['symbol'] + \"_\" + pfm['tf_class']\n",
    "        tf_counter[id] += 1\n",
    "        pfm['id'] = id + \"_\" + str(tf_counter[id])\n",
    "        pfm['source'] = \"Taipale 2013\"\n",
    "        taipale_pfms.append(pfm)\n",
    "\n",
    "print(json.dumps(taipale_pfms[:1], indent=4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"info\": [\n",
      "            \"BCL6B\",\n",
      "            \"C2H2\",\n",
      "            \"DBD\",\n",
      "            \"TGCGGG20NGA\",\n",
      "            \"AC\",\n",
      "            \"TGCTTTCTAGGAATTMM\",\n",
      "            \"2\",\n",
      "            \"4\",\n",
      "            \"monomeric\",\n",
      "            \"\",\n",
      "            \"yes\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\",\n",
      "            \"\"\n",
      "        ],\n",
      "        \"PFM\": [\n",
      "            [\n",
      "                0,\n",
      "                3,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                280,\n",
      "                0,\n",
      "                0,\n",
      "                289,\n",
      "                290,\n",
      "                0,\n",
      "                0,\n",
      "                113,\n",
      "                183\n",
      "            ],\n",
      "            [\n",
      "                19,\n",
      "                0,\n",
      "                367,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                384,\n",
      "                12,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                2,\n",
      "                16,\n",
      "                243,\n",
      "                146\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                186,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                2,\n",
      "                0,\n",
      "                34,\n",
      "                0,\n",
      "                173,\n",
      "                171,\n",
      "                2,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                9,\n",
      "                7\n",
      "            ],\n",
      "            [\n",
      "                207,\n",
      "                1,\n",
      "                2,\n",
      "                212,\n",
      "                213,\n",
      "                212,\n",
      "                0,\n",
      "                214,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "                215,\n",
      "                211,\n",
      "                0,\n",
      "                0\n",
      "            ]\n",
      "        ],\n",
      "        \"symbol\": \"BCL6B\",\n",
      "        \"tf_class\": \"C2H2\",\n",
      "        \"id\": \"BCL6B_C2H2_1\",\n",
      "        \"source\": \"Taipale 2013\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "all_pfms = jaspar_pfms + hoco_pfms + taipale_pfms\n",
    "\n",
    "with open(\"json/all_pfms.json\", 'w') as f:\n",
    "    json.dump(all_pfms, f, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('3.9.7': pyenv)"
  },
  "interpreter": {
   "hash": "72a66ab61caac5f0291fd728f3ab7736711cf078fef08edd42c58c2ff1f41239"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}